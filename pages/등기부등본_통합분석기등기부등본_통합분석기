import streamlit as st
import pandas as pd
import tempfile
import zipfile
import os
import re
from openpyxl import Workbook
from openpyxl.utils.dataframe import dataframe_to_rows
from openpyxl.styles import Alignment, PatternFill, Border, Side
from openpyxl.utils import get_column_letter
from PyPDF2 import PdfReader

# ============================
# ê¸°ë³¸ ì„¤ì •
# ============================
st.set_page_config(
    page_title="(ì£¼)ê±´í™” ë“±ê¸°ë¶€ë“±ë³¸ Excel í†µí•©ê¸°",
    layout="wide"
)

password = st.text_input('ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”', type='password')
if password != '126791':
    st.warning('ì˜¬ë°”ë¥¸ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.')
    st.stop()

st.title("ğŸ§¾ (ì£¼)ê±´í™” ë“±ê¸°ë¶€ë“±ë³¸ í†µí•©ë¶„ì„ê¸°")

# ============================
# ê²½ë¡œ ì •ì˜ (â˜… í•µì‹¬ ìˆ˜ì • í¬ì¸íŠ¸)
# ============================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
ASSETS_DIR = os.path.join(BASE_DIR, "assets")
MANUAL_PDF = os.path.join(ASSETS_DIR, "manual.pdf")

# ============================
# ê³µí†µ ë‹¤ìš´ë¡œë“œ ìœ í‹¸
# ============================
def download_button(label, file_path, mime, download_name=None):
    if not os.path.exists(file_path):
        st.error(f"íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {os.path.basename(file_path)}")
        st.caption(f"í™•ì¸ ê²½ë¡œ: {file_path}")
        return

    with open(file_path, "rb") as f:
        data = f.read()

    st.download_button(
        label=label,
        data=data,
        file_name=download_name or os.path.basename(file_path),
        mime=mime,
        use_container_width=True
    )

# ============================
# PDF ë§¤ë‰´ì–¼ (ë‹¤ìš´ë¡œë“œ ì „ìš© â€“ Streamlit Cloud ì•ˆì •)
# ============================
with st.expander("ğŸ“– ë§¤ë‰´ì–¼ ë³´ê¸°", expanded=False):
    if os.path.exists(MANUAL_PDF):
        download_button(
            label="ğŸ“„ PDF ë§¤ë‰´ì–¼ ë‹¤ìš´ë¡œë“œ",
            file_path=MANUAL_PDF,
            mime="application/pdf",
            download_name="ë“±ê¸°ë¶€ë“±ë³¸_ìë™ì •ë¦¬í”„ë¡œê·¸ë¨_Manual.pdf"
        )
        st.caption("â€» ë‹¤ìš´ë¡œë“œ í›„ ë¸Œë¼ìš°ì € ë˜ëŠ” PDF ë·°ì–´ì—ì„œ ì—´ì–´ì£¼ì„¸ìš”.")
    else:
        st.warning("assets/manual.pdf íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

st.markdown("""
### ì„œë¹„ìŠ¤ ì´ìš© ì•ˆë‚´
- **ë“±ê¸°ì‚¬í•­ì „ë¶€ì¦ëª…ì„œ(ì—´ëŒìš©)** Excel íŒŒì¼ë§Œ ì§€ì›ë©ë‹ˆë‹¤.
- Acrobat Proë¥¼ ì´ìš©í•´ ë“±ê¸°ë¶€ë“±ë³¸ PDFë¥¼ Excelë¡œ ë³€í™˜í•œ í›„, í•´ë‹¹ íŒŒì¼ë“¤ì„ **ZIP**ìœ¼ë¡œ ì••ì¶•í•´ ì—…ë¡œë“œí•˜ì„¸ìš”.
- ë°˜ë“œì‹œ ì •ì‹ ë°œê¸‰ëœ ì—´ëŒìš© ë¬¸ì„œë¥¼ ì‚¬ìš©í•´ ì£¼ì„¸ìš”.
- ë°œê¸‰ ì‹œ **ì£¼ìš” ë“±ê¸°ì‚¬í•­ ìš”ì•½ í˜ì´ì§€**ë¥¼ ë°˜ë“œì‹œ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
- ë“±ê¸°ë¶€ íŠ¹ì„±ìƒ í†µí•© ê³¼ì •ì—ì„œ ì¼ë¶€ ì£¼ìš” ë‚´ìš©ì´ ëˆ„ë½ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, **ì›ë³¸ëŒ€ì¡° ê²€í† **ê°€ í•„ìš”í•©ë‹ˆë‹¤.
""")


# ì—…ë¡œë“œì°½ 2ê°œë¡œ ë¶„ë¦¬ (ì—‘ì…€ ZIP, PDF ZIP)
uploaded_zip = st.file_uploader("ğŸ“ˆ EXCEL.zip íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (ë‚´ë¶€ì— .xlsx íŒŒì¼ í¬í•¨)", type=["zip"])
# PDF ZIP ì—…ë¡œë“œì°½ ì¶”ê°€
uploaded_pdf_zip = st.file_uploader("ğŸ“„ PDF.zip íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (ë‚´ë¶€ì— .pdf íŒŒì¼ í¬í•¨)", type=["zip"], key="pdf_zip")
run_button = st.button("ë¶„ì„ ì‹œì‘")

# ê²½ë¡œ ì„¤ì • (ì„ì‹œí´ë” ì‚¬ìš©)
upload_folder = tempfile.mkdtemp()
output_folder = tempfile.mkdtemp()

# ì£¼ì†Œ ì¶”ì¶œ ì •ê·œí‘œí˜„ì‹ íŒ¨í„´ (ë” í¬ê´„ì ìœ¼ë¡œ ìˆ˜ì •)
# ê¸°ì¡´ íŒ¨í„´ (ì¶©ì²­ë‚¨ë„ ì„œì‚°ì‹œ ëŒ€ì‚°ì ì „ìš©) - ì‚° ì§€ë²ˆ í¬í•¨
pattern_specific = re.compile(r'\[í† ì§€\]\s*(ì¶©ì²­ë‚¨ë„\s*ì„œì‚°ì‹œ\s*ëŒ€ì‚°ì\s*[ê°€-í£]+ë¦¬)\s*(ì‚°?\d+(?:-\d+)?)')

# ë™/ë¦¬ë¡œ ëë‚˜ëŠ” ì¼ë°˜ì ì¸ íŒ¨í„´ (ê°€ì¥ ë§ì´ ì‚¬ìš©ë¨) - ì‚° ì§€ë²ˆ í¬í•¨
pattern_dong_ri = re.compile(r'\[í† ì§€\]\s*([ê°€-í£]+[ë„ì‹œêµ°êµ¬ê´‘ì—­]\s*[ê°€-í£]+[ì‹œêµ°êµ¬]\s*[ê°€-í£]+[ìë©´ë™ë¦¬])\s*(ì‚°?\d+(?:-\d+)?)')

# ë” êµ¬ì²´ì ì¸ íŒ¨í„´ë“¤ - ì‚° ì§€ë²ˆ í¬í•¨
pattern_gwangyeoksi = re.compile(r'\[í† ì§€\]\s*([ê°€-í£]+ê´‘ì—­ì‹œ\s*[ê°€-í£]+êµ¬\s*[ê°€-í£]+ë™)\s*(ì‚°?\d+(?:-\d+)?)')
pattern_si_gu_dong = re.compile(r'\[í† ì§€\]\s*([ê°€-í£]+ì‹œ\s*[ê°€-í£]+êµ¬\s*[ê°€-í£]+ë™)\s*(ì‚°?\d+(?:-\d+)?)')
pattern_gun_eup_ri = re.compile(r'\[í† ì§€\]\s*([ê°€-í£]+[ë„]\s*[ê°€-í£]+[êµ°]\s*[ê°€-í£]+[ìë©´]\s*[ê°€-í£]+ë¦¬)\s*(ì‚°?\d+(?:-\d+)?)')

# ê°€ì¥ ìœ ì—°í•œ íŒ¨í„´ (ê³µë°±ê³¼ íŠ¹ìˆ˜ë¬¸ì ê³ ë ¤) - ì‚° ì§€ë²ˆ í¬í•¨
pattern_flexible = re.compile(r'\[í† ì§€\][\s]*([ê°€-í£\s]+[ë„ì‹œêµ°êµ¬ê´‘ì—­][\s]*[ê°€-í£\s]+[ì‹œêµ°êµ¬][\s]*[ê°€-í£\s]+[ìë©´ë™ë¦¬])[\s]*(ì‚°?\d+(?:-\d+)?)')

# ì‚° ì§€ë²ˆ ì „ìš© íŒ¨í„´ (ë” ëª…í™•í•œ ë§¤ì¹­ì„ ìœ„í•´)
pattern_san_specific = re.compile(r'\[í† ì§€\]\s*([ê°€-í£]+[ë„ì‹œêµ°êµ¬ê´‘ì—­]\s*[ê°€-í£]+[ì‹œêµ°êµ¬]\s*[ê°€-í£]+[ìë©´ë™ë¦¬])\s*ì‚°\s*(\d+(?:-\d+)?)')
pattern_san_flexible = re.compile(r'\[í† ì§€\][\s]*([ê°€-í£\s]+[ë„ì‹œêµ°êµ¬ê´‘ì—­][\s]*[ê°€-í£\s]+[ì‹œêµ°êµ¬][\s]*[ê°€-í£\s]+[ìë©´ë™ë¦¬])[\s]*ì‚°[\s]*(\d+(?:-\d+)?)')

def extract_address_from_pdf_text(text):
    """
    PDF í…ìŠ¤íŠ¸ì—ì„œ ì£¼ì†Œë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜ (ì—¬ëŸ¬ íŒ¨í„´ ì‹œë„)
    ì‚° ì§€ë²ˆë„ í¬í•¨í•˜ì—¬ ì²˜ë¦¬
    """
    patterns = [
        (pattern_san_specific, "ì‚°ì§€ë²ˆ íŠ¹ì •íŒ¨í„´"),
        (pattern_san_flexible, "ì‚°ì§€ë²ˆ ìœ ì—°íŒ¨í„´"),
        (pattern_specific, "íŠ¹ì •íŒ¨í„´(ì„œì‚°)"),
        (pattern_gwangyeoksi, "ê´‘ì—­ì‹œíŒ¨í„´"),
        (pattern_si_gu_dong, "ì‹œêµ¬ë™íŒ¨í„´"),
        (pattern_gun_eup_ri, "êµ°ìë¦¬íŒ¨í„´"),
        (pattern_dong_ri, "ë™ë¦¬íŒ¨í„´"),
        (pattern_flexible, "ìœ ì—°íŒ¨í„´")
    ]
    
    for pattern, pattern_type in patterns:
        match = pattern.search(text)
        if match:
            address = match.group(1)
            # ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ì˜ ê³µë°±ìœ¼ë¡œ í†µì¼
            address = re.sub(r'\s+', ' ', address)
            lot_no = match.group(2)
            
            # ì‚° ì§€ë²ˆì˜ ê²½ìš° íŒŒì¼ëª…ì— "ì‚°" í¬í•¨
            if "ì‚°ì§€ë²ˆ" in pattern_type:
                lot_no = f"ì‚°{lot_no}"
            elif lot_no.startswith("ì‚°"):
                # ì´ë¯¸ "ì‚°"ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ê²½ìš°ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€
                pass
            
            return address, lot_no, pattern_type
    
    return None, None, None

def process_pdf_files(folder_path):
    """
    PDF íŒŒì¼ë“¤ì˜ íŒŒì¼ëª…ì„ ì£¼ì†Œ ê¸°ë°˜ìœ¼ë¡œ ë³€ê²½í•˜ëŠ” í•¨ìˆ˜
    """
    success_count = 0
    failure_count = 0
    error_summary = {}
    successful_samples = []
    failed_samples = []
    
    total_files = len([f for f in os.listdir(folder_path) if f.lower().endswith(".pdf")])
    
    # ì§„í–‰ë¥  í‘œì‹œìš©
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for i, filename in enumerate(os.listdir(folder_path)):
        if filename.lower().endswith(".pdf"):
            # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
            progress = (i + 1) / total_files
            progress_bar.progress(progress)
            status_text.text(f"ì²˜ë¦¬ ì¤‘... {i + 1}/{total_files} ({progress:.1%})")
            
            full_path = os.path.join(folder_path, filename)
            try:
                reader = PdfReader(full_path)
                
                # PDFê°€ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸
                if len(reader.pages) == 0:
                    error_type = "PDF í˜ì´ì§€ ì—†ìŒ"
                    error_summary[error_type] = error_summary.get(error_type, 0) + 1
                    if len(failed_samples) < 5:
                        failed_samples.append(f"{filename} - {error_type}")
                    failure_count += 1
                    continue
                    
                first_page_text = reader.pages[0].extract_text()
                
                # í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨ í™•ì¸
                if not first_page_text or first_page_text.strip() == "":
                    error_type = "í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨"
                    error_summary[error_type] = error_summary.get(error_type, 0) + 1
                    if len(failed_samples) < 5:
                        failed_samples.append(f"{filename} - {error_type}")
                    failure_count += 1
                    continue

                # ìƒˆë¡œìš´ ì£¼ì†Œ ì¶”ì¶œ í•¨ìˆ˜ ì‚¬ìš©
                address, lot_no, pattern_type = extract_address_from_pdf_text(first_page_text)
                
                if address and lot_no:
                    new_filename = f"{address}_{lot_no}.pdf"
                    new_path = os.path.join(folder_path, new_filename)

                    # íŒŒì¼ëª… ì¤‘ë³µ ë°©ì§€
                    if not os.path.exists(new_path):
                        os.rename(full_path, new_path)
                        success_count += 1
                        if len(successful_samples) < 5:
                            successful_samples.append(f"{filename} â†’ {new_filename} ({pattern_type})")
                    else:
                        error_type = "íŒŒì¼ëª… ì¤‘ë³µ"
                        error_summary[error_type] = error_summary.get(error_type, 0) + 1
                        if len(failed_samples) < 5:
                            failed_samples.append(f"{filename} - {error_type}")
                        failure_count += 1
                else:
                    error_type = "ì£¼ì†Œ íŒ¨í„´ ë¯¸ë°œê²¬"
                    error_summary[error_type] = error_summary.get(error_type, 0) + 1
                    if len(failed_samples) < 5:
                        failed_samples.append(f"{filename} - {error_type}")
                    failure_count += 1
                    
            except Exception as e:
                error_type = f"ì²˜ë¦¬ ì˜¤ë¥˜: {type(e).__name__}"
                error_summary[error_type] = error_summary.get(error_type, 0) + 1
                if len(failed_samples) < 5:
                    failed_samples.append(f"{filename} - {str(e)[:50]}...")
                failure_count += 1
    
    # ì§„í–‰ë¥  ë°” ì™„ë£Œ
    progress_bar.progress(1.0)
    status_text.text("ì²˜ë¦¬ ì™„ë£Œ!")
    
    # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
    st.write("---")
    st.write(f"## ğŸ“Š PDF íŒŒì¼ëª… ë³€ê²½ ê²°ê³¼")
    
    # ì„±ê³µ/ì‹¤íŒ¨ í†µê³„
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("âœ… ì„±ê³µ", success_count)
    with col2:
        st.metric("âŒ ì‹¤íŒ¨", failure_count)
    with col3:
        st.metric("ğŸ“ ì „ì²´", total_files)
    
    # ì„±ê³µë¥  í‘œì‹œ
    success_rate = (success_count / total_files * 100) if total_files > 0 else 0
    st.write(f"**ì„±ê³µë¥ : {success_rate:.1f}%**")
    
    # ì„±ê³µ ì‚¬ë¡€ ìƒ˜í”Œ (ìµœëŒ€ 5ê°œ)
    if successful_samples:
        st.write("### âœ… ì„±ê³µ ì‚¬ë¡€ (ìƒ˜í”Œ)")
        for sample in successful_samples:
            st.write(f"- {sample}")
        if success_count > 5:
            st.write(f"... ì™¸ {success_count - 5}ê°œ ë”")
    
    # ì‹¤íŒ¨ ìœ í˜•ë³„ ìš”ì•½
    if error_summary:
        st.write("### âŒ ì‹¤íŒ¨ ìœ í˜•ë³„ í†µê³„")
        for error_type, count in error_summary.items():
            percentage = (count / failure_count * 100) if failure_count > 0 else 0
            st.write(f"- **{error_type}**: {count}ê°œ ({percentage:.1f}%)")
        
        # ì‹¤íŒ¨ ì‚¬ë¡€ ìƒ˜í”Œ (ìµœëŒ€ 5ê°œ)
        if failed_samples:
            st.write("### ğŸ” ì‹¤íŒ¨ ì‚¬ë¡€ (ìƒ˜í”Œ)")
            for sample in failed_samples:
                st.write(f"- {sample}")
            if failure_count > 5:
                st.write(f"... ì™¸ {failure_count - 5}ê°œ ë”")
    
    return success_count, failure_count

def extract_and_process_pdf_zip(zip_file, extract_to, output_zip):
    # ì••ì¶• í•´ì œ
    with zipfile.ZipFile(zip_file, 'r') as zip_ref:
        zip_ref.extractall(extract_to)
    # PDF íŒŒì¼ ì²˜ë¦¬
    process_pdf_files(extract_to)
    # ê²°ê³¼ ì••ì¶•íŒŒì¼ ìƒì„±
    with zipfile.ZipFile(output_zip, 'w') as zip_out:
        for root, _, files in os.walk(extract_to):
            for file in files:
                full_path = os.path.join(root, file)
                arcname = os.path.relpath(full_path, extract_to)
                zip_out.write(full_path, arcname)

def merge_adjacent_cells(row_series, max_gap=3):
    """
    ì¸ì ‘í•œ ì…€ë“¤ì„ ë³‘í•©í•˜ì—¬ í•˜ë‚˜ì˜ ì˜ë¯¸ìˆëŠ” ë‹¨ìœ„ë¡œ ë§Œë“œëŠ” í•¨ìˆ˜
    ë°ì´í„° í–‰ì—ì„œëŠ” ë” ì‹ ì¤‘í•˜ê²Œ ë³‘í•©
    """
    merged_row = row_series.copy()
    row_dict = row_series.to_dict()
    
    # ë¹ˆ ì…€ì´ ì•„ë‹Œ ì…€ë“¤ì˜ ì¸ë±ìŠ¤ë¥¼ ì°¾ê¸°
    non_empty_indices = [idx for idx, val in row_dict.items() if str(val).strip()]
    
    # ë°ì´í„°ê°€ ë„ˆë¬´ ì ê±°ë‚˜ ë§ìœ¼ë©´ ë³‘í•©í•˜ì§€ ì•ŠìŒ (í—¤ë”ê°€ ì•„ë‹Œ ê²½ìš°)
    if len(non_empty_indices) < 2 or len(non_empty_indices) > 10:
        return merged_row
    
    # ì—°ì†ëœ ì…€ë“¤ì„ ê·¸ë£¹í™” (ë” ì—„ê²©í•œ ì¡°ê±´)
    groups = []
    current_group = []
    
    for i, idx in enumerate(non_empty_indices):
        if not current_group:
            current_group = [idx]
        else:
            # ì´ì „ ì¸ë±ìŠ¤ì™€ì˜ ê±°ë¦¬ê°€ 2 ì´í•˜ë©´ ê°™ì€ ê·¸ë£¹ (ë” ì—„ê²©í•˜ê²Œ)
            if idx - current_group[-1] <= 2:
                current_group.append(idx)
            else:
                # ìƒˆë¡œìš´ ê·¸ë£¹ ì‹œì‘
                groups.append(current_group)
                current_group = [idx]
    
    if current_group:
        groups.append(current_group)
    
    # ê° ê·¸ë£¹ ë‚´ì˜ ì…€ë“¤ì„ ë³‘í•© (ë” ì‹ ì¤‘í•˜ê²Œ)
    for group in groups:
        if len(group) > 1 and len(group) <= 3:  # ë„ˆë¬´ ë§ì€ ì…€ì€ ë³‘í•©í•˜ì§€ ì•ŠìŒ
            # ê·¸ë£¹ ë‚´ ëª¨ë“  ê°’ì„ ì—°ê²°
            merged_value = ""
            for idx in group:
                val = str(row_dict.get(idx, "")).strip()
                if val:
                    if merged_value and not merged_value.endswith((" ", "-", "/")):
                        merged_value += " "
                    merged_value += val
            
            # ì²« ë²ˆì§¸ ì¸ë±ìŠ¤ì— ë³‘í•©ëœ ê°’ ì €ì¥
            merged_row[group[0]] = merged_value
            
            # ë‚˜ë¨¸ì§€ ì¸ë±ìŠ¤ëŠ” ë¹ˆ ê°’ìœ¼ë¡œ ì„¤ì •
            for idx in group[1:]:
                merged_row[idx] = ""
    
    return merged_row

def merge_dataframe_cells(df, is_header_row=False):
    """
    ë°ì´í„°í”„ë ˆì„ì— ì…€ ë³‘í•© ë¡œì§ ì ìš©
    í—¤ë” í–‰ê³¼ ë°ì´í„° í–‰ì„ êµ¬ë¶„í•˜ì—¬ ì²˜ë¦¬
    """
    if df.empty:
        return df
    
    merged_df = df.copy()
    
    # ì²« ë²ˆì§¸ í–‰ì€ í—¤ë”ë¡œ ê°€ì •í•˜ê³  ë” ê´€ëŒ€í•˜ê²Œ ë³‘í•©
    if len(merged_df) > 0:
        merged_df.iloc[0] = merge_adjacent_cells(merged_df.iloc[0], max_gap=3)
    
    # ë‚˜ë¨¸ì§€ í–‰ë“¤ì€ ë°ì´í„° í–‰ìœ¼ë¡œ ë” ì—„ê²©í•˜ê²Œ ë³‘í•©
    for i in range(1, len(merged_df)):
        merged_df.iloc[i] = merge_adjacent_cells(merged_df.iloc[i], max_gap=2)
    
    return merged_df

def trim_after_reference_note(df):
    for i, row in df.iterrows():
        row_text = "".join(str(cell) for cell in row)
        normalized = re.sub(r"\s+", "", row_text)
        if "ì°¸ê³ ì‚¬í•­" in normalized or "ì°¸ê³ " in normalized or "ë¹„ê³ " in normalized:
            return df.iloc[:i]
    return df

def extract_identifier(df):
    """
    íŒŒì¼ì—ì„œ í† ì§€/ê±´ë¬¼ ì‹ë³„ìë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
    """
    for i in range(len(df)):
        row = df.iloc[i]
        row_text = " ".join(str(cell) for cell in row if pd.notna(cell))
        if "ê³ ìœ ë²ˆí˜¸" in row_text:
            for j in range(i+1, min(i+10, len(df))):
                content = " ".join(str(cell) for cell in df.iloc[j] if pd.notna(cell))
                if content.strip().startswith(("[í† ì§€]", "[ê±´ë¬¼]")):
                    # ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ì˜ ê³µë°±ìœ¼ë¡œ í†µì¼
                    content = re.sub(r'\s+', ' ', content.strip())
                    return content
            break
    
    # ê³ ìœ ë²ˆí˜¸ ì´í›„ì— [í† ì§€] ë˜ëŠ” [ê±´ë¬¼]ì´ ì—†ëŠ” ê²½ìš°, ì „ì²´ ë°ì´í„°ì—ì„œ ì°¾ê¸°
    for i in range(len(df)):
        row_text = " ".join(str(cell) for cell in df.iloc[i] if pd.notna(cell))
        if row_text.strip().startswith(("[í† ì§€]", "[ê±´ë¬¼]")):
            # ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ì˜ ê³µë°±ìœ¼ë¡œ í†µì¼
            row_text = re.sub(r'\s+', ' ', row_text.strip())
            return row_text
            
    return "ì•Œìˆ˜ì—†ìŒ"

def convert_jibun_to_decimal(jibun_text):
    """
    ìµœì¢…ì§€ë¶„ í…ìŠ¤íŠ¸ë¥¼ ì†Œìˆ˜ì  í˜•íƒœë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
    ì˜ˆ: "2ë¶„ì˜ 1" -> 0.5, "1/2" -> 0.5, "50%" -> 0.5, "ë‹¨ë…ì†Œìœ " -> 1
    """
    if not jibun_text or pd.isna(jibun_text):
        return None
    
    jibun_text = str(jibun_text).strip()
    
    # ë‹¨ë…ì†Œìœ ëŠ” 1ë¡œ ë³€í™˜
    if "ë‹¨ë…ì†Œìœ " in jibun_text or (("ë‹¨ë…" in jibun_text) and len(jibun_text) < 10):
        return 1.0
    
    # 1) ë¶„ìˆ˜ í˜•íƒœ (ì˜ˆ: 1/2, 1/3, ê³µìœ 1/3 ë“±)
    fraction_match = re.search(r'(?:ê³µìœ )?(\d+)/(\d+)', jibun_text)
    if fraction_match:
        numerator = float(fraction_match.group(1))
        denominator = float(fraction_match.group(2))
        if denominator != 0:
            return numerator / denominator
    
    # 2) í¼ì„¼íŠ¸ í˜•íƒœ (ì˜ˆ: 50%, 33.3% ë“±)
    percent_match = re.search(r'([\d\.]+)\s*%', jibun_text)
    if percent_match:
        return float(percent_match.group(1)) / 100
    
    # 3) 'ë¶„ì˜' í˜•íƒœ (ì˜ˆ: 3ë¶„ì˜ 1, 2ë¶„ì˜ 1 ë“±)
    boonui_match = re.search(r'(\d+\.?\d*)\s*ë¶„\s*ì˜\s*(\d+\.?\d*)', jibun_text)
    if boonui_match:
        denominator = float(boonui_match.group(1))
        numerator = float(boonui_match.group(2))
        if denominator != 0:
            return numerator / denominator
    
    # 4) ë¶„ì˜ í˜•íƒœ - ë„ì–´ì“°ê¸° ì—†ëŠ” ê²½ìš° (ì˜ˆ: 10139.94ë¶„ì˜845.0298)
    boonui_match2 = re.search(r'(\d+\.?\d*)ë¶„ì˜(\d+\.?\d*)', jibun_text)
    if boonui_match2:
        denominator = float(boonui_match2.group(1))
        numerator = float(boonui_match2.group(2))
        if denominator != 0:
            return numerator / denominator
    
    return None

def keyword_match_partial(cell, keyword):
    if pd.isnull(cell): return False
    return keyword.replace(" ", "") in str(cell).replace(" ", "")

def keyword_match_exact(cell, keyword):
    if pd.isnull(cell): return False
    return re.sub(r"\s+", "", str(cell)) == re.sub(r"\s+", "", keyword)

def merge_split_headers(header_row):
    """ë¶„ë¦¬ëœ í—¤ë”ë¥¼ ë³‘í•©í•˜ëŠ” í•¨ìˆ˜ - ê°œì„ ëœ ë²„ì „"""
    # ì…€ ë³‘í•©ì„ í•˜ì§€ ì•Šê³  ì›ë³¸ í—¤ë”ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    merged_row = header_row.copy()
    
    # ê¸°ì¡´ íŠ¹ì • í‚¤ì›Œë“œ ë³‘í•© ë¡œì§ë§Œ ì ìš© (ì¸ì ‘ ì…€ ë³‘í•©ì€ ì œì™¸)
    split_patterns = {
        "ì£¼ì†Œ": ["ì£¼", "ì†Œ"],
        "ë“±ê¸°ëª…ì˜ì¸": ["ë“±ê¸°", "ëª…ì˜ì¸"],
        "ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸": ["ì£¼ë¯¼", "ë“±ë¡ë²ˆí˜¸"],
        "ìµœì¢…ì§€ë¶„": ["ìµœì¢…", "ì§€ë¶„"],
        "ìˆœìœ„ë²ˆí˜¸": ["ìˆœìœ„", "ë²ˆí˜¸"],
        "ë“±ê¸°ëª©ì ": ["ë“±ê¸°", "ëª©ì "],
        "ì ‘ìˆ˜ì •ë³´": ["ì ‘ìˆ˜", "ì •ë³´"],
        "ì£¼ìš”ë“±ê¸°ì‚¬í•­": ["ì£¼ìš”", "ë“±ê¸°ì‚¬í•­"],
        "ëŒ€ìƒì†Œìœ ì": ["ëŒ€ìƒ", "ì†Œìœ ì"]
    }
    
    for target_keyword, split_parts in split_patterns.items():
        found_indices = []
        for part in split_parts:
            for idx, cell_value in merged_row.items():
                cell_str = str(cell_value).strip()
                if cell_str == part:
                    found_indices.append(idx)
                    break
        
        if len(found_indices) == len(split_parts):
            if all(found_indices[i+1] - found_indices[i] <= 2 for i in range(len(found_indices)-1)):
                merged_row[found_indices[0]] = target_keyword
                for idx in found_indices[1:]:
                    merged_row[idx] = ""
    
    return merged_row

def enhanced_keyword_match(header_row, keyword, max_distance=2):
    """ì¸ì ‘í•œ ì…€ë“¤ì„ ê³ ë ¤í•œ í‚¤ì›Œë“œ ë§¤ì¹­ - ê°œì„ ëœ ë²„ì „"""
    # ë¨¼ì € ì •í™•í•œ ë§¤ì¹­ ì‹œë„
    for idx, cell in header_row.items():
        if keyword_match_exact(cell, keyword):
            return idx
    
    # ë¶€ë¶„ ë§¤ì¹­ ì‹œë„
    for idx, cell in header_row.items():
        if keyword_match_partial(cell, keyword):
            return idx
    
    # ë¶„ë¦¬ëœ í‚¤ì›Œë“œ ë§¤ì¹­ ì‹œë„ (ë” ì—„ê²©í•˜ê²Œ)
    keyword_chars = list(keyword.replace(" ", ""))
    if len(keyword_chars) <= 1:
        return None
    
    for start_idx, cell in header_row.items():
        if str(cell).strip() == keyword_chars[0]:
            # ì²« ê¸€ìê°€ ë§¤ì¹­ë˜ë©´ ë‹¤ìŒ ê¸€ìë“¤ì„ ì¸ì ‘ ì…€ì—ì„œ ì°¾ê¸°
            current_text = str(cell).strip()
            current_idx = start_idx
            
            for i in range(1, len(keyword_chars)):
                found_next = False
                # ìµœëŒ€ max_distanceê¹Œì§€ ë–¨ì–´ì§„ ì…€ì—ì„œ ë‹¤ìŒ ê¸€ì ì°¾ê¸°
                for offset in range(1, max_distance + 1):
                    next_idx = current_idx + offset
                    if next_idx in header_row:
                        next_cell = str(header_row[next_idx]).strip()
                        if next_cell == keyword_chars[i]:
                            current_text += next_cell
                            current_idx = next_idx
                            found_next = True
                            break
                
                if not found_next:
                    break
            
            # ì „ì²´ í‚¤ì›Œë“œê°€ ë§¤ì¹­ë˜ì—ˆëŠ”ì§€ í™•ì¸
            if current_text == keyword.replace(" ", ""):
                return start_idx
    
    return None

def extract_section_range(df, start_kw, end_kw_list, match_fn):
    df = df.fillna("")
    df.columns = range(df.shape[1])
    start_idx, end_idx = None, len(df)
    for i, row in df.iterrows():
        if any(match_fn(cell, start_kw) for cell in row):
            start_idx = i + 1
            break
    if start_idx is None:
        return pd.DataFrame(), False
    for i in range(start_idx, len(df)):
        row = df.iloc[i]
        if any(any(match_fn(cell, end_kw) for cell in row) for end_kw in end_kw_list):
            end_idx = i
            break
    section = df.iloc[start_idx:end_idx].copy()
    is_empty = section.replace("", pd.NA).dropna(how="all").empty
    return section if not is_empty else pd.DataFrame([["ê¸°ë¡ì—†ìŒ"]]), not is_empty

# ì†Œìœ ì§€ë¶„í˜„í™©(ê°‘êµ¬)ì—ì„œ í•„ìš”í•œ ì—´ì„ ì¶”ì¶œ
def extract_named_cols(section, col_keywords):
    if section.empty:
        return pd.DataFrame([["ê¸°ë¡ì—†ìŒ"]])
    
    # ì…€ ë³‘í•© ì ìš© (í—¤ë”ì™€ ë°ì´í„° êµ¬ë¶„)
    section = merge_dataframe_cells(section)
    
    header_row = section.iloc[0]
    merged_header = merge_split_headers(header_row)
    
    col_map = {}
    for target in col_keywords:
        col_idx = enhanced_keyword_match(merged_header, target)
        if col_idx is not None:
            col_map[target] = col_idx

    # ìµœì¢…ì§€ë¶„ íŠ¹ë³„ ì²˜ë¦¬ (ê¸°ì¡´ ë¡œì§ ìœ ì§€í•˜ë˜ ë” ì •í™•í•˜ê²Œ)
    if "ìµœì¢…ì§€ë¶„" not in col_map:
        idx_ìµœì¢… = None
        idx_ì§€ë¶„ = None
        for idx, val in merged_header.items():
            val_str = str(val).strip()
            if val_str == "ìµœì¢…":
                idx_ìµœì¢… = idx
            elif val_str == "ì§€ë¶„":
                idx_ì§€ë¶„ = idx
        
        if idx_ìµœì¢… is not None and idx_ì§€ë¶„ is not None and abs(idx_ìµœì¢… - idx_ì§€ë¶„) <= 2:
            col_map["ìµœì¢…ì§€ë¶„"] = (min(idx_ìµœì¢…, idx_ì§€ë¶„), max(idx_ìµœì¢…, idx_ì§€ë¶„))

    rows = []
    for i in range(1, len(section)):
        row = section.iloc[i]
        row_dict = {}
        
        for key in col_keywords:
            if key == "ìµœì¢…ì§€ë¶„":
                if isinstance(col_map.get("ìµœì¢…ì§€ë¶„"), tuple):
                    idx1, idx2 = col_map["ìµœì¢…ì§€ë¶„"]
                    val1 = str(row.get(idx1, "")).strip()
                    val2 = str(row.get(idx2, "")).strip()
                    if val1 and val2:
                        row_dict[key] = val1 + val2
                    else:
                        row_dict[key] = val1 or val2
                elif isinstance(col_map.get("ìµœì¢…ì§€ë¶„"), int):
                    idx = col_map["ìµœì¢…ì§€ë¶„"]
                    val1 = str(row.get(idx, "")).strip()
                    # ì¸ì ‘ ì…€ í™•ì¸ì€ í—¤ë”ê°€ ë¹„ì–´ìˆì„ ë•Œë§Œ
                    val2 = ""
                    if (idx + 1) in row and not str(merged_header.get(idx + 1, "")).strip():
                        val2 = str(row.get(idx + 1, "")).strip()
                    if val1 and val2:
                        row_dict[key] = val1 + val2
                    else:
                        row_dict[key] = val1
                else:
                    row_dict[key] = ""
            elif key in col_map:
                col_idx = col_map[key]
                cell_value = row.get(col_idx, "")
                row_dict[key] = str(cell_value).strip() if pd.notna(cell_value) else ""
            else:
                row_dict[key] = ""
        
        # ë°ì´í„° ì •ë¦¬: ë“±ê¸°ëª…ì˜ì¸ì— ë‹¤ë¥¸ ì •ë³´ê°€ ì„ì—¬ìˆëŠ” ê²½ìš° ë¶„ë¦¬
        if "ë“±ê¸°ëª…ì˜ì¸" in row_dict:
            owner_text = str(row_dict["ë“±ê¸°ëª…ì˜ì¸"]).strip()
            
            # ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸ ë¶„ë¦¬
            if "(ì£¼ë¯¼)ë“±ë¡ë²ˆí˜¸" in col_keywords:
                jumin = extract_jumin_number(owner_text)
                if jumin:
                    row_dict["(ì£¼ë¯¼)ë“±ë¡ë²ˆí˜¸"] = jumin
                    owner_text = owner_text.replace(jumin, "").strip()
            
            # ì§€ë¶„ ì •ë³´ ë¶„ë¦¬
            if "ìµœì¢…ì§€ë¶„" in col_keywords and not row_dict.get("ìµœì¢…ì§€ë¶„"):
                extracted_jibun = extract_jibun(owner_text)
                if extracted_jibun:
                    row_dict["ìµœì¢…ì§€ë¶„"] = extracted_jibun
                    owner_text = owner_text.replace(extracted_jibun, "").strip()
            
            # ì£¼ì†Œ ì •ë³´ ë¶„ë¦¬
            if "ì£¼ì†Œ" in col_keywords and not row_dict.get("ì£¼ì†Œ"):
                if is_address_pattern(owner_text):
                    # ì´ë¦„ê³¼ ì£¼ì†Œë¥¼ ë¶„ë¦¬í•˜ë ¤ê³  ì‹œë„
                    parts = owner_text.split()
                    if len(parts) > 1:
                        # ì²« ë²ˆì§¸ ë¶€ë¶„ì´ ì´ë¦„ì´ê³  ë‚˜ë¨¸ì§€ê°€ ì£¼ì†Œì¼ ê°€ëŠ¥ì„±
                        possible_name = parts[0]
                        possible_address = " ".join(parts[1:])
                        if is_address_pattern(possible_address):
                            row_dict["ë“±ê¸°ëª…ì˜ì¸"] = possible_name.replace(" ", "")  # ì´ë¦„ ë„ì–´ì“°ê¸° ì œê±°
                            row_dict["ì£¼ì†Œ"] = possible_address
                            continue
            
            # ì •ë¦¬ëœ ë“±ê¸°ëª…ì˜ì¸ ì„¤ì • (ë„ì–´ì“°ê¸° ì œê±°)
            row_dict["ë“±ê¸°ëª…ì˜ì¸"] = owner_text.replace(" ", "")
            
        rows.append(row_dict)
    
    return pd.DataFrame(rows)

def find_keyword_header(section, col_keywords, max_search_rows=15):
    section = section.fillna("").astype(str)
    for i in range(min(max_search_rows, len(section))):
        row = section.iloc[i]
        match_count = sum(any(keyword_match_exact(cell, kw) for cell in row) for kw in col_keywords)
        if match_count >= 3:
            return i, row
    return None, None

def find_col_index(header_row, keyword):
    for idx, val in header_row.items():
        if keyword_match_exact(val, keyword):
            return idx
    return None

# ì†Œìœ ê¶Œì‚¬í•­ (ê°‘êµ¬)ì™€ ì—ì„œ í•„ìš”í•œ ì—´ ì¶”ì¶œ
def extract_precise_named_cols(section, col_keywords):
    # ì…€ ë³‘í•©ì„ í•˜ì§€ ì•Šê³  ì›ë³¸ ì„¹ì…˜ ì‚¬ìš©
    section = section.copy()
    # always use first row as header
    header_row = merge_split_headers(section.iloc[0])
    start_row = 1
    
    col_map = {}
    for key in col_keywords:
        idx = find_col_index(header_row, key)
        # fallback to partial match if exact failed
        if idx is None:
            for i, val in header_row.items():
                if keyword_match_partial(val, key):
                    idx = i
                    break
        if idx is not None:
            col_map[key] = idx

    if not col_map:
       # ëª¨ë“  ì»¬ëŸ¼ì— ëŒ€í•´ ë¹ˆ ê°’ì„ ìƒì„±í•˜ê³ , ì²«ë²ˆì§¸ ì»¬ëŸ¼ì—ë§Œ "ê¸°ë¡ì—†ìŒ" í‘œì‹œ
       result = pd.DataFrame(columns=col_keywords)
       result.loc[0] = [""] * len(col_keywords)
       result.iloc[0, 0] = "ê¸°ë¡ì—†ìŒ"
       return result

    rows = []
    for i in range(start_row, len(section)):
        row = section.iloc[i]
        row_dict = {}
        for key in col_keywords:
            if key in col_map:
                # í•´ë‹¹ ì—´ì˜ ì •í™•í•œ ì¸ë±ìŠ¤ì—ì„œë§Œ ê°’ ê°€ì ¸ì˜¤ê¸°
                col_idx = col_map[key]
                if col_idx < len(row):
                    cell_value = row.iloc[col_idx]
                    row_dict[key] = str(cell_value).strip() if pd.notna(cell_value) else ""
                else:
                    row_dict[key] = ""
            else:
                row_dict[key] = ""
        rows.append(row_dict)
    return pd.DataFrame(rows)
def merge_same_row_if_amount_separated(df):
    df = df.copy()
    for i in range(len(df) - 1):
        row = df.iloc[i]
        main = str(row["ì£¼ìš”ë“±ê¸°ì‚¬í•­"])

        if "ì±„ê¶Œìµœê³ ì•¡" in main:
            # í˜„ì¬ í–‰ê³¼ ë‹¤ìŒ í–‰ ëª¨ë‘ ë³‘í•© í…ìŠ¤íŠ¸ êµ¬ì„±
            combined_row = list(row.values) + list(df.iloc[i + 1].values)
            combined_text = " ".join(str(x) for x in combined_row if pd.notnull(x))

            # ê¸ˆì•¡ íŒ¨í„´ ì¶”ì¶œ
            match = re.search(r"ê¸ˆ[\d,]+ì›", combined_text)
            if match and match.group(0) not in main:
                df.at[i, "ì£¼ìš”ë“±ê¸°ì‚¬í•­"] = main + " " + match.group(0)
    return df
def is_jumin_number(text):
    """
    ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸ íŒ¨í„´ì„ í™•ì¸í•˜ëŠ” í•¨ìˆ˜
    ì˜ˆ: 123456-1234567 ë˜ëŠ” 123456-*******
    """
    if not isinstance(text, str):
        return False
    
    # ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸ íŒ¨í„´ (ìˆ«ì6ìë¦¬-ìˆ«ìë˜ëŠ”*)
    pattern = re.compile(r'\d{6}-[\d\*]+')
    return bool(re.search(pattern, text))

def extract_jumin_number(text):
    """
    ë¬¸ìì—´ì—ì„œ ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸ íŒ¨í„´ì„ ì¶”ì¶œ
    """
    if not isinstance(text, str):
        return ""
    
    pattern = re.compile(r'\d{6}-[\d\*]+')
    match = re.search(pattern, text)
    return match.group(0) if match else ""

def is_jibun_pattern(text):
    """
    ìµœì¢…ì§€ë¶„ íŒ¨í„´ì„ í™•ì¸í•˜ëŠ” í•¨ìˆ˜
    ì˜ˆ: 1/2, 50%, 3ë¶„ì˜ 1, ê³µìœ 1/3, ë‹¨ë…ì†Œìœ  ë“±
    """
    if not isinstance(text, str):
        return False
    
    # í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìœ¼ë©´ ì§€ë¶„ íŒ¨í„´ ì•„ë‹˜
    if not text.strip():
        return False
    
    # "ë‹¨ë…ì†Œìœ " í‚¤ì›Œë“œ í™•ì¸
    if "ë‹¨ë…ì†Œìœ " in text or "ë‹¨ë…" in text:
        return True
    
    # ë¶„ìˆ˜ íŒ¨í„´ (ì˜ˆ: 1/2, 1/3, ê³µìœ 1/3 ë“±)
    pattern1 = re.compile(r'(?:ê³µìœ )?[\d]+[/][\d]+')
    # í¼ì„¼íŠ¸ íŒ¨í„´ (ì˜ˆ: 50%, 33.3% ë“±)
    pattern2 = re.compile(r'[\d]+[.]?[\d]*\s*%')
    # 'ë¶„ì˜' íŒ¨í„´ (ì˜ˆ: 3ë¶„ì˜ 1, 2ë¶„ì˜ 1 ë“±)
    pattern3 = re.compile(r'[\d]+\.?[\d]*\s*ë¶„\s*ì˜\s*[\d]+\.?[\d]*')
    # ë¶„ì˜ íŒ¨í„´ - ë„ì–´ì“°ê¸° ì—†ëŠ” ê²½ìš° (ì˜ˆ: 10139.94ë¶„ì˜845.0298)
    pattern4 = re.compile(r'[\d]+\.?[\d]*ë¶„ì˜[\d]+\.?[\d]*')
    
    return (bool(re.search(pattern1, text)) or 
            bool(re.search(pattern2, text)) or 
            bool(re.search(pattern3, text)) or 
            bool(re.search(pattern4, text)))

def is_address_pattern(text):
    """
    ì£¼ì†Œ íŒ¨í„´ì„ í™•ì¸í•˜ëŠ” í•¨ìˆ˜
    """
    if not isinstance(text, str):
        return False
    
    # "ë‹¨ë…ì†Œìœ " í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ì£¼ì†Œê°€ ì•„ë‹˜
    if "ë‹¨ë…ì†Œìœ " in text or "ë‹¨ë…" in text:
        return False
    
    # ì£¼ì†Œì— í”íˆ í¬í•¨ë˜ëŠ” í‚¤ì›Œë“œ
    address_keywords = ['ì‹œ', 'ë„', 'êµ°', 'êµ¬', 'ì', 'ë©´', 'ë™', 'ë¡œ', 'ê¸¸', 'ì•„íŒŒíŠ¸', 'ë¹Œë¼', 'ë²ˆì§€']
    text_no_space = re.sub(r'\s+', '', text)
    
    for kw in address_keywords:
        if kw in text_no_space:
            return True
            
    return False

def extract_jibun(text):
    """
    ë¬¸ìì—´ì—ì„œ ì§€ë¶„ íŒ¨í„´ ì¶”ì¶œ
    """
    if not isinstance(text, str):
        return ""
    
    # "ë‹¨ë…ì†Œìœ " í‚¤ì›Œë“œ í™•ì¸
    if "ë‹¨ë…ì†Œìœ " in text:
        return "ë‹¨ë…ì†Œìœ "
    elif "ë‹¨ë…" in text and len(text.strip()) < 10:  # "ë‹¨ë…" ë‹¨ì–´ë§Œ ìˆê³  ê¸¸ì´ê°€ ì§§ì€ ê²½ìš°
        return "ë‹¨ë…ì†Œìœ "
    
    # ë¶„ìˆ˜ íŒ¨í„´ (ì˜ˆ: 1/2, 1/3, ê³µìœ 1/3 ë“±)
    pattern1 = re.compile(r'(?:ê³µìœ )?[\d]+[/][\d]+')
    # í¼ì„¼íŠ¸ íŒ¨í„´ (ì˜ˆ: 50%, 33.3% ë“±)
    pattern2 = re.compile(r'[\d]+[.]?[\d]*\s*%')
    # 'ë¶„ì˜' íŒ¨í„´ - ë„ì–´ì“°ê¸° ìˆëŠ” ê²½ìš° (ì˜ˆ: 3ë¶„ì˜ 1, 10139.94ë¶„ ì˜ 845.0298)
    pattern3 = re.compile(r'[\d]+\.?[\d]*\s*ë¶„\s*ì˜\s*[\d]+\.?[\d]*')
    # ë¶„ì˜ íŒ¨í„´ - ë„ì–´ì“°ê¸° ì—†ëŠ” ê²½ìš° (ì˜ˆ: 10139.94ë¶„ì˜845.0298)
    pattern4 = re.compile(r'[\d]+\.?[\d]*ë¶„ì˜[\d]+\.?[\d]*')
    
    # ê° íŒ¨í„´ ìˆœì„œëŒ€ë¡œ í™•ì¸
    match1 = re.search(pattern1, text)
    if match1:
        return match1.group(0)
    
    match2 = re.search(pattern2, text)
    if match2:
        return match2.group(0)
    
    match3 = re.search(pattern3, text)
    if match3:
        return match3.group(0)
    
    match4 = re.search(pattern4, text)
    if match4:
        return match4.group(0)
    
    return ""

def extract_ownership_type(owner_name):
    """
    ë“±ê¸°ëª…ì˜ì¸ ë¬¸ìì—´ì—ì„œ ì†Œìœ êµ¬ë¶„ ì •ë³´(ì†Œìœ ì, ê³µìœ ì ë“±)ë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
    """
    if not isinstance(owner_name, str):
        return "", owner_name
    
    # (ì†Œìœ ì), (ê³µìœ ì) íŒ¨í„´ ì°¾ê¸°
    pattern = r'\((ì†Œìœ ì|ê³µìœ ì)\)'
    match = re.search(pattern, owner_name)
    
    if match:
        ownership_type = match.group(1)  # 'ì†Œìœ ì' ë˜ëŠ” 'ê³µìœ ì' ì¶”ì¶œ
        clean_name = owner_name.replace(match.group(0), "").strip()  # íŒ¨í„´ ì œê±°
        return ownership_type, clean_name
    else:
        return "", owner_name

def extract_land_type(df):
    """
    ì—‘ì…€ íŒŒì¼ì—ì„œ í† ì§€ ì§€ëª© ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
    """
    land_type = ""
    # ë” êµ¬ì²´ì ì´ê³  ê¸´ ë‹¨ì–´ê°€ ë¨¼ì € ê²€ì‚¬ë˜ë„ë¡ ì •ë ¬
    land_types = ["ê³µì¥ìš©ì§€", "ì¡ì¢…ì§€", "ì—¼ì „", "ë„ë¡œ", "ì„ì•¼", "ìœ ì§€", "í•˜ì²œ", "êµ¬ê±°", "ì œë°©", "ì–‘ì–´ì¥","ì „", "ë‹µ", "ëŒ€","ê´‘ì²œì§€","ìˆ˜ë„ìš©ì§€","ì œë°©","ì—¼ì „","ê³¼ìˆ˜ì›","ëª©ì¥ìš©ì§€","í•™êµìš©ì§€","ì¢…êµìš©ì§€","ì£¼ì°¨ì¥","ì£¼ìœ ì†Œ","ì°½ê³ ìš©ì§€","ì² ë„ìš©ì§€","ê³µì›","ë¬˜ì§€","ì²´ìœ¡ìš©ì§€","ìœ ì›ì§€","ì‚¬ì ì§€","ì¡ì¢…ì§€"]
    
    # 1. ì£¼ìš” ë“±ê¸°ì‚¬í•­ ìš”ì•½ ì„¹ì…˜ì—ì„œ í† ì§€ ì§€ëª© ì¶”ì¶œ ì‹œë„ (ìµœìš°ì„ )
    summary_row_idx = None
    for i in range(len(df)):
        row_text = " ".join(str(cell) for cell in df.iloc[i] if pd.notna(cell))
        if "ì£¼ìš” ë“±ê¸°ì‚¬í•­ ìš”ì•½" in row_text or "ì£¼ìš”ë“±ê¸°ì‚¬í•­ìš”ì•½" in re.sub(r'\s+', '', row_text):
            summary_row_idx = i
            break
    
    if summary_row_idx is not None:
        # ìš”ì•½ ì„¹ì…˜ ì´í›„ í† ì§€ ì •ë³´ ê²€ìƒ‰
        for i in range(summary_row_idx + 1, min(summary_row_idx + 10, len(df))):
            row_text = " ".join(str(cell) for cell in df.iloc[i] if pd.notna(cell))
            if "[í† ì§€]" in row_text:
                # ì§€ëª© ì •ë³´ë¥¼ ë” ì •í™•í•˜ê²Œ ì¶”ì¶œ
                for lt in land_types:
                    # [í† ì§€] ë‹¤ìŒì— ì˜¤ëŠ” ì§€ëª© ì •ë³´ ì°¾ê¸°
                    pattern = r'\[í† ì§€\][^ê°€-í£]*' + lt + r'(?:\s|$|[^ê°€-í£])'
                    if re.search(pattern, row_text):
                        return lt
                    # ê°„ë‹¨í•œ íŒ¨í„´ë„ í™•ì¸
                    if lt in row_text and "[í† ì§€]" in row_text:
                        # ì£¼ë³€ ë¬¸ë§¥ í™•ì¸í•˜ì—¬ ì‹¤ì œ ì§€ëª©ì¸ì§€ íŒë‹¨
                        lt_index = row_text.find(lt)
                        land_index = row_text.find("[í† ì§€]")
                        if abs(lt_index - land_index) < 50:  # 50ì ì´ë‚´ì— ìˆìœ¼ë©´ ê´€ë ¨ì„± ìˆìŒ
                            return lt
    
    # 2. íŒŒì¼ ì‹ë³„ìì—ì„œ ì§€ëª© ì •ë³´ ì¶”ì¶œ ì‹œë„
    identifier = extract_identifier(df)
    if "[í† ì§€]" in identifier:
        # ì •í™•í•œ ë§¤ì¹­ì„ ìœ„í•œ íŒ¨í„´: ì•ë’¤ë¡œ ê³µë°±ì´ë‚˜ ë¬¸ì¥ ëì¸ ê²½ìš°ë§Œ ë§¤ì¹­
        for lt in land_types:
            pattern = r'(^|\s|[^ê°€-í£])' + lt + r'($|\s|[^ê°€-í£])'
            if re.search(pattern, identifier):
                land_type = lt
                break
                
        # ì •í™•í•œ ë§¤ì¹­ì´ ì•ˆ ëœ ê²½ìš° ë¶€ë¶„ ë§¤ì¹­ìœ¼ë¡œ ì‹œë„ (ë‹¨, ë” ì—„ê²©í•˜ê²Œ)
        if not land_type:
            for lt in land_types:
                if lt in identifier and "[í† ì§€]" in identifier:
                    # ì§€ëª©ì´ [í† ì§€] ê·¼ì²˜ì— ìˆëŠ”ì§€ í™•ì¸
                    lt_index = identifier.find(lt)
                    land_index = identifier.find("[í† ì§€]")
                    if abs(lt_index - land_index) < 30:  # 30ì ì´ë‚´
                        land_type = lt
                        break
    
    # 3. ë°ì´í„°í”„ë ˆì„ ì „ì²´ì—ì„œ ì°¾ê¸° (ë” ì‹ ì¤‘í•˜ê²Œ)
    if not land_type:
        for i in range(len(df)):
            row_text = " ".join(str(cell) for cell in df.iloc[i] if pd.notna(cell))
            
            # [í† ì§€] í‚¤ì›Œë“œê°€ ìˆëŠ” í–‰ ìš°ì„  ê²€ìƒ‰
            if "[í† ì§€]" in row_text:
                for lt in land_types:
                    pattern = r'(^|\s|[^ê°€-í£])' + lt + r'($|\s|[^ê°€-í£])'
                    if re.search(pattern, row_text):
                        return lt
                
                # ì •í™•í•œ ë§¤ì¹­ì´ ì•ˆ ë˜ë©´ ë¶€ë¶„ ë§¤ì¹­ ì‹œë„ (ë‹¨, [í† ì§€] ê·¼ì²˜ì—ì„œë§Œ)
                for lt in land_types:
                    if lt in row_text:
                        lt_index = row_text.find(lt)
                        land_index = row_text.find("[í† ì§€]")
                        if abs(lt_index - land_index) < 30:
                            return lt
            
            # ì§€ëª©ê³¼ ë©´ì ì´ í•¨ê»˜ ë‚˜ì˜¤ëŠ” íŒ¨í„´ ì°¾ê¸°
            for lt in land_types:
                if lt in row_text and ("ã¡" in row_text or "mÂ²" in row_text):
                    # ì§€ëª©ê³¼ ë©´ì ì´ ê°™ì€ í–‰ì— ìˆìœ¼ë©´ ì‹¤ì œ ì§€ëª©ì¼ ê°€ëŠ¥ì„± ë†’ìŒ
                    return lt
    
    return land_type if land_type else ""

def extract_land_area(df):
    """
    ì—‘ì…€ íŒŒì¼ì—ì„œ í† ì§€ë©´ì  ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
    ë‹¤ì–‘í•œ í˜•ì‹ì˜ ë©´ì  í‘œê¸°ë¥¼ ì¸ì‹
    """
    area = ""
    land_types = ["ì—¼ì „", "ë„ë¡œ", "ì„ì•¼", "ìœ ì§€", "ë‹µ", "ì „", "ëŒ€", "ê³µì¥ìš©ì§€", "ì¡ì¢…ì§€", "í•˜ì²œ", "êµ¬ê±°", "ì œë°©", "ì–‘ì–´ì¥"]
    
    # ì£¼ìš” ë“±ê¸°ì‚¬í•­ ìš”ì•½ ì„¹ì…˜ì—ì„œ ë©´ì  ì¶”ì¶œ ì‹œë„
    summary_row_idx = None
    for i in range(len(df)):
        row_text = " ".join(str(cell) for cell in df.iloc[i] if pd.notna(cell))
        if "ì£¼ìš” ë“±ê¸°ì‚¬í•­ ìš”ì•½" in row_text or "ì£¼ìš”ë“±ê¸°ì‚¬í•­ìš”ì•½" in re.sub(r'\s+', '', row_text):
            summary_row_idx = i
            break
    
    if summary_row_idx is not None:
        # ìš”ì•½ ì„¹ì…˜ ì´í›„ í† ì§€ ì •ë³´ ê²€ìƒ‰
        for i in range(summary_row_idx + 1, min(summary_row_idx + 10, len(df))):
            row_text = " ".join(str(cell) for cell in df.iloc[i] if pd.notna(cell))
            if "[í† ì§€]" in row_text:
                area_match = re.search(r'(\d[\d,\.]*)\s*[ã¡mÂ²]', row_text)
                if area_match:
                    return area_match.group(1).replace(',', '')
    
    # ì´í•˜ ê¸°ì¡´ ì¶”ì¶œ ë°©ë²• (ìœ„ ë°©ë²•ì´ ì‹¤íŒ¨í•œ ê²½ìš° ì‹¤í–‰)
    # íŒŒì¼ ì‹ë³„ìì—ì„œ ë©´ì  ì¶”ì¶œ ì‹œë„
    identifier = extract_identifier(df)
    if "[í† ì§€]" in identifier:
        # ë©´ì  íŒ¨í„´ ì°¾ê¸°: "[í† ì§€]" ë¬¸ì¥ ë‚´ì—ì„œ ìˆ«ì + ã¡ ë˜ëŠ” mÂ² íŒ¨í„´
        area_match = re.search(r'(\d[\d,\.]*)\s*[ã¡mÂ²]', identifier)
        if area_match:
            return area_match.group(1).replace(',', '')
    
    # ë°ì´í„°í”„ë ˆì„ ì „ì²´ì—ì„œ ì°¾ê¸°
    for i in range(len(df)):
        row_text = " ".join(str(cell) for cell in df.iloc[i] if pd.notna(cell))
        
        # í† ì§€ì¢…ë¥˜ê°€ ìˆëŠ” í–‰ì—ì„œ ë©´ì  íŒ¨í„´ ì°¾ê¸°
        if any(land_type in row_text for land_type in land_types):
            # ë©´ì  íŒ¨í„´: ìˆ«ì + ã¡ ë˜ëŠ” mÂ² íŒ¨í„´
            area_match = re.search(r'(\d[\d,\.]*)\s*[ã¡mÂ²]', row_text)
            if area_match:
                area = area_match.group(1).replace(',', '')
                break
            
        # "[í† ì§€]" íŒ¨í„´ì´ ìˆëŠ” í–‰ì—ì„œ ì°¾ê¸°
        if "[í† ì§€]" in row_text:
            area_match = re.search(r'(\d[\d,\.]*)\s*[ã¡mÂ²]', row_text)
            if area_match:
                area = area_match.group(1).replace(',', '')
                break
    
    return area

def check_san_in_address(address):
    """
    í† ì§€ì£¼ì†Œì— 'ì‚°'ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ëŠ” í•¨ìˆ˜
    'ì‚°'ì´ ìˆ«ì ì•ì— ìˆìœ¼ë©´ 'O', ì•„ë‹ˆë©´ 'X'
    """
    if not isinstance(address, str):
        return ''
    
    # ì£¼ì†Œì—ì„œ ë§ˆì§€ë§‰ ë¶€ë¶„ì„ ê°€ì ¸ì˜¤ê¸°
    parts = address.split()
    if not parts:
        return ''
    
    # ì£¼ì†Œì˜ ë§ˆì§€ë§‰ ë¶€ë¶„ì—ì„œ 'ì‚°' ë‹¤ìŒì— ìˆ«ìê°€ ì˜¤ëŠ” íŒ¨í„´ í™•ì¸
    import re
    for part in parts:
        if re.search(r'ì‚°\d+', part) or re.search(r'ì‚°\s*\d+', part):
            return 'ì‚°'
    return ''

def extract_right_holders(df):
    """
    ì£¼ìš”ë“±ê¸°ì‚¬í•­ì—ì„œ ê·¼ì €ë‹¹ê¶Œìì™€ ì§€ìƒê¶Œì ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê³ , 
    ì›ë³¸ í…ìŠ¤íŠ¸ì—ì„œ í•´ë‹¹ ì •ë³´ë¥¼ ì œê±°í•˜ëŠ” í•¨ìˆ˜
    """
    df = df.copy()
    df["ê·¼ì €ë‹¹ê¶Œì"] = ""
    df["ì§€ìƒê¶Œì"] = ""
    
    for idx, row in df.iterrows():
        if "ì£¼ìš”ë“±ê¸°ì‚¬í•­" not in row or pd.isna(row["ì£¼ìš”ë“±ê¸°ì‚¬í•­"]):
            continue
            
        main_text = str(row["ì£¼ìš”ë“±ê¸°ì‚¬í•­"])
        modified_text = main_text
        
        # ê·¼ì €ë‹¹ê¶Œì ì¶”ì¶œ ë° ì œê±°
        mortgage_pattern = r'ê·¼ì €ë‹¹ê¶Œì\s*[:ï¼š]?\s*([^,\n]*)'
        mortgage_match = re.search(mortgage_pattern, main_text)
        if mortgage_match:
            df.at[idx, "ê·¼ì €ë‹¹ê¶Œì"] = mortgage_match.group(1).strip()
            # ì „ì²´ ë§¤ì¹˜ ë¶€ë¶„ì„ ì°¾ì•„ ì œê±° (ê·¼ì €ë‹¹ê¶Œì: XXX í˜•íƒœ ì „ì²´)
            full_match = mortgage_match.group(0)
            modified_text = modified_text.replace(full_match, "")
        
        # ì§€ìƒê¶Œì ì¶”ì¶œ ë° ì œê±°
        surface_pattern = r'ì§€ìƒê¶Œì\s*[:ï¼š]?\s*([^,\n]*)'
        surface_match = re.search(surface_pattern, modified_text)
        if surface_match:
            df.at[idx, "ì§€ìƒê¶Œì"] = surface_match.group(1).strip()
            # ì „ì²´ ë§¤ì¹˜ ë¶€ë¶„ì„ ì°¾ì•„ ì œê±° (ì§€ìƒê¶Œì: XXX í˜•íƒœ ì „ì²´)
            full_match = surface_match.group(0)
            modified_text = modified_text.replace(full_match, "")
        
        # ìˆ˜ì •ëœ í…ìŠ¤íŠ¸ ì •ë¦¬ (ì•ë’¤ ê³µë°±, ì‰¼í‘œ ì •ë¦¬)
        modified_text = modified_text.strip()
        modified_text = re.sub(r',\s*,', ',', modified_text)  # ì—°ì†ëœ ì‰¼í‘œ ì œê±°
        modified_text = re.sub(r'^\s*,\s*|\s*,\s*$', '', modified_text)  # ì‹œì‘/ëì˜ ì‰¼í‘œ ì œê±°
        
        # ì •ë¦¬ëœ í…ìŠ¤íŠ¸ë¡œ ì—…ë°ì´íŠ¸
        df.at[idx, "ì£¼ìš”ë“±ê¸°ì‚¬í•­"] = modified_text
    
    return df

def style_header_row(ws):
    """ì›Œí¬ì‹œíŠ¸ í—¤ë” í–‰ì„ ìŠ¤íƒ€ì¼ë§í•˜ëŠ” í•¨ìˆ˜"""
    # ì—°í•œ ì´ˆë¡ìƒ‰ ë°°ê²½ ì„¤ì • (RGB: 230, 244, 234)
    light_green_fill = PatternFill(start_color="E6F4EA", end_color="E6F4EA", fill_type="solid")
    
    # í…Œë‘ë¦¬ ìŠ¤íƒ€ì¼ ì •ì˜
    thin_border = Border(
        left=Side(style='thin', color='000000'),
        right=Side(style='thin', color='000000'),
        top=Side(style='thin', color='000000'),
        bottom=Side(style='thin', color='000000')
    )
    
    # ì²« ë²ˆì§¸ í–‰ (í—¤ë”) ìŠ¤íƒ€ì¼ ì ìš©
    for cell in ws[1]:
        # ì¤‘ì•™ ì •ë ¬
        cell.alignment = Alignment(horizontal='center', vertical='center')
        # ì—°í•œ ì´ˆë¡ìƒ‰ ë°°ê²½
        cell.fill = light_green_fill
        # í…Œë‘ë¦¬ ì¶”ê°€
        cell.border = thin_border
    
    # í—¤ë” í–‰ ë†’ì´ ì¡°ì •
    ws.row_dimensions[1].height = 25
    
    # ì—´ ë„ˆë¹„ ìë™ ì¡°ì • (ë‚´ìš©ì— ë”°ë¼)
    for col in ws.columns:
        max_length = 0
        col_letter = get_column_letter(col[0].column)
        # ê° ì…€ì˜ ë‚´ìš© ê¸¸ì´ í™•ì¸
        for cell in col:
            try:
                cell_length = len(str(cell.value)) if cell.value else 0
                max_length = max(max_length, cell_length)
            except:
                pass
        # ìµœì†Œ 10, ìµœëŒ€ 50 ì‚¬ì´ë¡œ ë„ˆë¹„ ì¡°ì •
        adjusted_width = min(max(max_length + 2, 10), 50)
        ws.column_dimensions[col_letter].width = adjusted_width

def apply_top_border_on_change(ws, key_column_letter='A', start_row=3):
    """
    Aì—´ ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ ì´ì „ í–‰ê³¼ ê°’ì´ ë‹¤ë¥¼ ë•Œ í˜„ì¬ í–‰ì— Top Border ì¶”ê°€
    ê¸°ë³¸ì ìœ¼ë¡œ 3í–‰ë¶€í„° ì ìš© (í—¤ë” 2ì¤„ ê³ ë ¤)
    """
    thin_top = Side(style='thin', color='000000')

    previous_value = None
    for row in range(start_row, ws.max_row + 1):
        cell = ws[f"{key_column_letter}{row}"]
        current_value = str(cell.value).strip() if cell.value is not None else ""

        if current_value != previous_value:
            for col in range(1, ws.max_column + 1):
                target = ws.cell(row=row, column=col)
                target.border = Border(
                    top=thin_top,
                    bottom=target.border.bottom,
                    left=target.border.left,
                    right=target.border.right
                )
        previous_value = current_value

def create_grouped_headers(ws, df, group_structure):
    """
    ì›Œí¬ì‹œíŠ¸ì— ê·¸ë£¹í™”ëœ í—¤ë”ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
    group_structure: {ê·¸ë£¹ëª…: [ì»¬ëŸ¼ëª… ë¦¬ìŠ¤íŠ¸]} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬
    """
    # ì²« ë²ˆì§¸ í–‰ - ê·¸ë£¹ í—¤ë”
    row_index = 1
    col_index = 1
    
    # ì—°í•œ ì´ˆë¡ìƒ‰ ë°°ê²½ ì„¤ì • (RGB: 230, 244, 234)
    light_green_fill = PatternFill(start_color="E6F4EA", end_color="E6F4EA", fill_type="solid")
    
    # í…Œë‘ë¦¬ ìŠ¤íƒ€ì¼ ì •ì˜
    thin_border = Border(
        left=Side(style='thin', color='000000'),
        right=Side(style='thin', color='000000'),
        top=Side(style='thin', color='000000'),
        bottom=Side(style='thin', color='000000')
    )
    
    # ê·¸ë£¹ í—¤ë” í–‰ ì¶”ê°€
    for group_name, columns in group_structure.items():
        # ê·¸ë£¹ ì´ë¦„ ì…€
        group_cell = ws.cell(row=row_index, column=col_index)
        group_cell.value = group_name
        group_cell.alignment = Alignment(horizontal='center', vertical='center')
        group_cell.fill = light_green_fill
        group_cell.border = thin_border
        
        # ì—¬ëŸ¬ ì—´ì— ê±¸ì³ ë³‘í•©
        if len(columns) > 1:
            ws.merge_cells(start_row=row_index, start_column=col_index, 
                          end_row=row_index, end_column=col_index + len(columns) - 1)
            
            # ë³‘í•©ëœ ì…€ì— í…Œë‘ë¦¬ ì¶”ê°€ (ë³‘í•© í›„ì— ëª¨ë“  ì…€ì— í…Œë‘ë¦¬ ì ìš©)
            for c in range(col_index, col_index + len(columns)):
                cell = ws.cell(row=row_index, column=c)
                cell.border = thin_border
        
        col_index += len(columns)
    
    # ë‘ ë²ˆì§¸ í–‰ - ì„¸ë¶€ í—¤ë”
    row_index = 2
    col_index = 1
    
    for _, columns in group_structure.items():
        for col_name in columns:
            col_cell = ws.cell(row=row_index, column=col_index)
            col_cell.value = col_name
            col_cell.alignment = Alignment(horizontal='center', vertical='center')
            col_cell.fill = light_green_fill
            col_cell.border = thin_border  # ê° ì—´ í—¤ë”ì— í…Œë‘ë¦¬ ì¶”ê°€
            col_index += 1
    
    # ë°ì´í„° ì¶”ê°€ (3ë²ˆì§¸ í–‰ë¶€í„°)
    row_index = 3
    for _, row in df.iterrows():
        col_index = 1
        for _, columns in group_structure.items():
            for col_name in columns:
                cell = ws.cell(row=row_index, column=col_index)
                cell.value = row.get(col_name, "")
                # ë°ì´í„° ì…€ì—ë„ ê°€ë²¼ìš´ í…Œë‘ë¦¬ ì¶”ê°€ (ì„ íƒì )
                cell.border = Border(
                    left=Side(style='thin', color='D3D3D3'),
                    right=Side(style='thin', color='D3D3D3'),
                    top=Side(style='thin', color='D3D3D3'),
                    bottom=Side(style='thin', color='D3D3D3')
                )
                col_index += 1
        row_index += 1
    
    # ì—´ ë„ˆë¹„ ìë™ ì¡°ì • (ë‚´ìš©ì— ë”°ë¼)
    for col in ws.columns:
        max_length = 0
        col_letter = get_column_letter(col[0].column)
        # ê° ì…€ì˜ ë‚´ìš© ê¸¸ì´ í™•ì¸
        for cell in col:
            try:
                cell_length = len(str(cell.value)) if cell.value else 0
                max_length = max(max_length, cell_length)
            except:
                pass
        # ìµœì†Œ 10, ìµœëŒ€ 50 ì‚¬ì´ë¡œ ë„ˆë¹„ ì¡°ì •
        adjusted_width = min(max(max_length + 2, 10), 50)
        ws.column_dimensions[col_letter].width = adjusted_width

def apply_borders_based_on_land_address(ws):
    """
    ê°™ì€ í† ì§€ì£¼ì†Œì¸ ê²½ìš° í…Œë‘ë¦¬ë¥¼ ìƒëµí•˜ê³ ,
    í† ì§€ì£¼ì†Œê°€ ë‹¬ë¼ì§€ëŠ” ê²½ìš° í•´ë‹¹ ì—´ ì „ì²´ì— ìœ„ì•„ë˜ í…Œë‘ë¦¬ë¥¼ ì¶”ê°€.
    """
    thin_border = Border(
        top=Side(style='thin', color='000000'),
        bottom=Side(style='thin', color='000000')
    )

    # í† ì§€ì£¼ì†Œ ì—´ì˜ ì¸ë±ìŠ¤ ì°¾ê¸°
    land_address_col = None
    for col in ws.iter_cols(min_row=1, max_row=1):
        for cell in col:
            if cell.value == "í† ì§€ì£¼ì†Œ":
                land_address_col = cell.column
                break
        if land_address_col:
            break

    if not land_address_col:
        return  # í† ì§€ì£¼ì†Œ ì—´ì´ ì—†ìœ¼ë©´ ì¢…ë£Œ

    previous_address = None
    for row in ws.iter_rows(min_row=2):
        current_address = row[land_address_col - 1].value
        if current_address != previous_address:
            for cell in row:
                cell.border = thin_border
        previous_address = current_address

# ê¸°ì¡´ ì½”ë“œì— ì ìš©
if run_button and uploaded_zip:
    # 1. ì—‘ì…€ ZIP ì²˜ë¦¬
    temp_dir = tempfile.mkdtemp()
    szj_list, syg_list, djg_list = [], [], []
    
    # ZIP íŒŒì¼ ì••ì¶• í•´ì œ
    with zipfile.ZipFile(uploaded_zip, "r") as z:
        z.extractall(temp_dir)
    
    # ì—‘ì…€ íŒŒì¼ ëª©ë¡ ìƒì„±
    excel_files = []
    for root, _, files in os.walk(temp_dir):
        for f in files:
            if f.lower().endswith(".xlsx"):
                excel_files.append(os.path.join(root, f))
    
    # UI ìš”ì•½ í†µê³„ ë³€ìˆ˜ (ê¸°ì¡´ ë¡œì§ê³¼ ë³„ë„ë¡œ ê´€ë¦¬)
    excel_success_count = 0
    excel_failure_count = 0
    excel_error_summary = {}
    excel_successful_samples = []
    excel_failed_samples = []
    
    total_excel_files = len(excel_files)
    
    if total_excel_files > 0:
        # ì§„í–‰ë¥  í‘œì‹œìš© UI
        excel_progress_bar = st.progress(0)
        excel_status_text = st.empty()
        st.write(f"## ğŸ“Š ì—‘ì…€ íŒŒì¼ ë³€í™˜ ì§„í–‰ ì¤‘...")
    
    # ê¸°ì¡´ ì—‘ì…€ ì²˜ë¦¬ ë¡œì§ (ì ˆëŒ€ ë³€ê²½í•˜ì§€ ì•ŠìŒ)
    for i, path in enumerate(excel_files):
        # UI ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ë§Œ ì¶”ê°€
        if total_excel_files > 0:
            progress = (i + 1) / total_excel_files
            excel_progress_bar.progress(progress)
            excel_status_text.text(f"ì—‘ì…€ ì²˜ë¦¬ ì¤‘... {i + 1}/{total_excel_files} ({progress:.1%})")
        
        file_name = os.path.basename(path)
        try:
            xls = pd.ExcelFile(path)
            df = xls.parse(xls.sheet_names[0]).fillna("")
            name = extract_identifier(df)
            land_area = extract_land_area(df)
            land_type = extract_land_type(df)
            szj_sec, has_szj = extract_section_range(df, "ì†Œìœ ì§€ë¶„í˜„í™©", ["ì†Œìœ ê¶Œ", "ì €ë‹¹ê¶Œ"], match_fn=keyword_match_partial)
            syg_sec, has_syg = extract_section_range(df, "ì†Œìœ ì§€ë¶„ì„ì œì™¸í•œì†Œìœ ê¶Œì—ê´€í•œì‚¬í•­", ["ì €ë‹¹ê¶Œ"], match_fn=keyword_match_partial)
            djg_sec, has_djg = extract_section_range(df, "3.(ê·¼)ì €ë‹¹ê¶Œë°ì „ì„¸ê¶Œë“±(ì„êµ¬)", ["ì°¸ê³ ", "ë¹„ê³ ", "ì´ê³„", "ì „ì‚°ìë£Œ"], match_fn=keyword_match_exact)
            
            # UI í†µê³„ìš© ì²˜ë¦¬ ê²°ê³¼ ë¶„ë¥˜ (ê¸°ì¡´ ë¡œì§ì— ì˜í–¥ ì—†ìŒ)
            sections_found = []
            if has_szj: sections_found.append("ì†Œìœ ì§€ë¶„í˜„í™©")
            if has_syg: sections_found.append("ì†Œìœ ê¶Œì‚¬í•­") 
            if has_djg: sections_found.append("ì €ë‹¹ê¶Œì‚¬í•­")
            
            if sections_found:
                excel_success_count += 1
                if len(excel_successful_samples) < 5:
                    excel_successful_samples.append(f"{file_name} â†’ {name} (ì„¹ì…˜: {', '.join(sections_found)})")
            else:
                error_type = "í•„ìš” ì„¹ì…˜ ë¯¸ë°œê²¬"
                excel_error_summary[error_type] = excel_error_summary.get(error_type, 0) + 1
                if len(excel_failed_samples) < 5:
                    excel_failed_samples.append(f"{file_name} â†’ {name} ({error_type})")
                excel_failure_count += 1
            
            if has_szj:
                szj_df = extract_named_cols(szj_sec, ["ë“±ê¸°ëª…ì˜ì¸", "(ì£¼ë¯¼)ë“±ë¡ë²ˆí˜¸", "ìµœì¢…ì§€ë¶„", "ì£¼ì†Œ", "ìˆœìœ„ë²ˆí˜¸"])
                szj_df["ì†Œìœ êµ¬ë¶„"] = ""
                for idx, row in szj_df.iterrows():
                    if pd.notna(row["ë“±ê¸°ëª…ì˜ì¸"]):
                        ownership_type, clean_name = extract_ownership_type(str(row["ë“±ê¸°ëª…ì˜ì¸"]))
                        szj_df.at[idx, "ì†Œìœ êµ¬ë¶„"] = ownership_type
                        szj_df.at[idx, "ë“±ê¸°ëª…ì˜ì¸"] = clean_name.replace(" ", "")  # ë“±ê¸°ëª…ì˜ì¸ ë„ì–´ì“°ê¸° ì œê±°
                    if pd.notna(row["ë“±ê¸°ëª…ì˜ì¸"]):
                        jumin = extract_jumin_number(str(row["ë“±ê¸°ëª…ì˜ì¸"]))
                        if jumin:
                            szj_df.at[idx, "(ì£¼ë¯¼)ë“±ë¡ë²ˆí˜¸"] = jumin
                            szj_df.at[idx, "ë“±ê¸°ëª…ì˜ì¸"] = str(row["ë“±ê¸°ëª…ì˜ì¸"]).replace(jumin, "").strip().replace(" ", "")  # ë„ì–´ì“°ê¸° ì œê±°
                    address_text = str(row["ì£¼ì†Œ"]).strip()
                    jibun_text = str(row["ìµœì¢…ì§€ë¶„"]).strip()
                    if pd.notna(row["ì£¼ì†Œ"]) and is_jibun_pattern(address_text):
                        jibun_in_address = extract_jibun(address_text)
                        if jibun_in_address:
                            # ìµœì¢…ì§€ë¶„ì´ ë¹„ì–´ìˆê±°ë‚˜, ì£¼ì†Œì—ì„œ ë°œê²¬í•œ ì§€ë¶„ì´ ë” ì •í™•í•´ ë³´ì´ëŠ” ê²½ìš°
                            if not jibun_text or len(jibun_in_address) > len(jibun_text):
                                szj_df.at[idx, "ìµœì¢…ì§€ë¶„"] = jibun_in_address
                            # ì£¼ì†Œì—ì„œëŠ” ì§€ë¶„ ì •ë³´ ì œê±°
                            szj_df.at[idx, "ì£¼ì†Œ"] = address_text.replace(jibun_in_address, "").strip()
                    if pd.notna(row["ìµœì¢…ì§€ë¶„"]) and is_address_pattern(jibun_text):
                        # ì£¼ì†Œ í•„ë“œê°€ ë¹„ì–´ìˆê±°ë‚˜ ìµœì¢…ì§€ë¶„ì˜ í…ìŠ¤íŠ¸ê°€ ë” ê¸¸ë©´(ìƒì„¸ ì£¼ì†Œì¼ ê°€ëŠ¥ì„±)
                        if not address_text or (len(jibun_text) > len(address_text)):
                            szj_df.at[idx, "ì£¼ì†Œ"] = jibun_text
                            szj_df.at[idx, "ìµœì¢…ì§€ë¶„"] = ""
                # ë§ˆì§€ë§‰ ê²€ì¦ - ë‹¨ë…ì†Œìœ  í™•ì¸
                for idx, row in szj_df.iterrows():
                    address_text = str(row["ì£¼ì†Œ"]).strip()
                    if "ë‹¨ë…" in address_text and "ë‹¨ë…ì†Œìœ " not in str(row["ìµœì¢…ì§€ë¶„"]):
                        # ë‹¨ë… í…ìŠ¤íŠ¸ê°€ ì£¼ì†Œì— ìˆê³  ìµœì¢…ì§€ë¶„ì— ì—†ìœ¼ë©´ ì´ë™
                        szj_df.at[idx, "ìµœì¢…ì§€ë¶„"] = "ë‹¨ë…ì†Œìœ "
                        szj_df.at[idx, "ì£¼ì†Œ"] = re.sub(r'ë‹¨ë…(?:ì†Œìœ )?', '', address_text).strip()
                # ìµœì¢…ì§€ë¶„ì—ì„œ ì£¼ì†Œ ì •ë³´ ì œê±°í•˜ê¸°
                for idx, row in szj_df.iterrows():
                    jibun_text = str(row["ìµœì¢…ì§€ë¶„"]).strip()
                    
                    # ìµœì¢…ì§€ë¶„ì—ì„œ ì§€ë¶„ íŒ¨í„´ ì¶”ì¶œ
                    if jibun_text and pd.notna(row["ìµœì¢…ì§€ë¶„"]):
                        if "ë‹¨ë…ì†Œìœ " in jibun_text or "ë‹¨ë…" in jibun_text and len(jibun_text) < 10:
                            # ë‹¨ë…ì†Œìœ ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€
                            szj_df.at[idx, "ìµœì¢…ì§€ë¶„"] = "ë‹¨ë…ì†Œìœ "
                        else:
                            # ì§€ë¶„ íŒ¨í„´ë§Œ ì¶”ì¶œ
                            extracted_jibun = extract_jibun(jibun_text)
                            if extracted_jibun:
                                szj_df.at[idx, "ìµœì¢…ì§€ë¶„"] = extracted_jibun
                            else:
                                # ì£¼ì†Œ íŒ¨í„´ í™•ì¸ í›„ ì£¼ì†Œë¼ë©´ í•´ë‹¹ í•„ë“œë¥¼ ë¹„ì›€
                                if is_address_pattern(jibun_text):
                                    if str(row["ì£¼ì†Œ"]).strip() == "":
                                        szj_df.at[idx, "ì£¼ì†Œ"] = jibun_text
                                    szj_df.at[idx, "ìµœì¢…ì§€ë¶„"] = ""
                # í† ì§€ë©´ì  ì—´ ì¶”ê°€
                szj_df["ì§€ëª©"] = land_type      # ì§€ëª© ì—´ ì¶”ê°€
                szj_df["í† ì§€ë©´ì "] = land_area
                # ì†Œìœ ë©´ì  ê³„ì‚° ë° ì—´ ì¶”ê°€
                szj_df["ì§€ë¶„ë©´ì "] = None
                for idx, row in szj_df.iterrows():
                    try:
                        jibun_decimal = convert_jibun_to_decimal(row["ìµœì¢…ì§€ë¶„"])
                        if jibun_decimal is not None and pd.notna(row["í† ì§€ë©´ì "]) and row["í† ì§€ë©´ì "]:
                            land_area_value = float(str(row["í† ì§€ë©´ì "]).replace(',', ''))
                            ownership_area = land_area_value * jibun_decimal
                            szj_df.at[idx, "ì§€ë¶„ë©´ì "] = f"{ownership_area:.4f}"
                    except Exception as e:
                        pass  # ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒì‹œ None ê°’ ìœ ì§€
                # ìµœì¢…ì§€ë¶„ ìˆ˜ì¹˜í™” ì—´ ì¶”ê°€
                szj_df["ìµœì¢…ì§€ë¶„ ìˆ˜ì¹˜í™”"] = None
                for idx, row in szj_df.iterrows():
                    try:
                        jibun_decimal = convert_jibun_to_decimal(row["ìµœì¢…ì§€ë¶„"])
                        if jibun_decimal is not None:
                            szj_df.at[idx, "ìµœì¢…ì§€ë¶„ ìˆ˜ì¹˜í™”"] = jibun_decimal
                    except Exception as e:
                        pass  # ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒì‹œ None ê°’ ìœ ì§€
                # ì—´ ìˆœì„œ ì¬ë°°ì¹˜
                szj_df.insert(0, "í† ì§€ì£¼ì†Œ", name)
                columns = ["í† ì§€ì£¼ì†Œ", "ë“±ê¸°ëª…ì˜ì¸", "ì†Œìœ êµ¬ë¶„", "(ì£¼ë¯¼)ë“±ë¡ë²ˆí˜¸", "ì£¼ì†Œ", "ìˆœìœ„ë²ˆí˜¸", "ìµœì¢…ì§€ë¶„", "ìµœì¢…ì§€ë¶„ ìˆ˜ì¹˜í™”", "ì§€ëª©", "í† ì§€ë©´ì ", "ì§€ë¶„ë©´ì "]
                szj_df = szj_df[columns]
                szj_df["ê·¸ë£¹ì •ë³´"] = "ìˆìŒ"  # ê·¸ë£¹ í—¤ë”ë¥¼ ì‚¬ìš©í•  ë°ì´í„° í”Œë˜ê·¸
                szj_list.append(szj_df)
            else:
                # "ê¸°ë¡ì—†ìŒ" ì¼€ì´ìŠ¤ì—ë„ ë™ì¼í•œ ì»¬ëŸ¼ êµ¬ì¡° ìœ ì§€
                szj_list.append(pd.DataFrame([[name, "ê¸°ë¡ì—†ìŒ", "", "", "", "", "", "", land_type, land_area, "", "ì—†ìŒ"]], 
                                             columns=["í† ì§€ì£¼ì†Œ", "ë“±ê¸°ëª…ì˜ì¸", "ì†Œìœ êµ¬ë¶„", "(ì£¼ë¯¼)ë“±ë¡ë²ˆí˜¸", "ì£¼ì†Œ", "ìˆœìœ„ë²ˆí˜¸", "ìµœì¢…ì§€ë¶„", "ìµœì¢…ì§€ë¶„ ìˆ˜ì¹˜í™”", "ì§€ëª©", "í† ì§€ë©´ì ", "ì§€ë¶„ë©´ì ", "ê·¸ë£¹ì •ë³´"]))
            if has_syg:
                syg_df = extract_precise_named_cols(syg_sec, ["ìˆœìœ„ë²ˆí˜¸", "ë“±ê¸°ëª©ì ", "ì ‘ìˆ˜ì •ë³´", "ì£¼ìš”ë“±ê¸°ì‚¬í•­", "ëŒ€ìƒì†Œìœ ì"])
                syg_df.insert(0, "í† ì§€ì£¼ì†Œ", name)
                syg_list.append(syg_df)
            else:
                syg_list.append(pd.DataFrame([[name, "ê¸°ë¡ì—†ìŒ"]], columns=["í† ì§€ì£¼ì†Œ", "ìˆœìœ„ë²ˆí˜¸"]))
            if has_djg:
                djg_df = extract_precise_named_cols(djg_sec, ["ìˆœìœ„ë²ˆí˜¸", "ë“±ê¸°ëª©ì ", "ì ‘ìˆ˜ì •ë³´", "ì£¼ìš”ë“±ê¸°ì‚¬í•­", "ëŒ€ìƒì†Œìœ ì"])
                
                # ë¹ˆ í–‰ ì œê±° - ë¹ˆ ë¬¸ìì—´ì„ NAë¡œ ë³€í™˜ í›„ ëª¨ë“  ê°’ì´ NAì¸ í–‰ ì œê±°
                djg_df = djg_df.replace('', pd.NA)
                djg_df = djg_df.dropna(how='all')
                
                # ê³µë°±ë§Œ ìˆëŠ” í–‰ë„ ì œê±° (ë¬¸ìì—´ì„ trimí•œ í›„ ë¹ˆ ë¬¸ìì—´ì¸ì§€ í™•ì¸)
                mask = ~djg_df.astype(str).apply(lambda row: row.str.strip().eq('').all(), axis=1)
                djg_df = djg_df[mask].reset_index(drop=True)
                
                # ë¹ˆ ê°’ì„ ë‹¤ì‹œ ë¹ˆ ë¬¸ìì—´ë¡œ ë³€í™˜
                djg_df = djg_df.fillna('')
                
                # "ëŒ€ìƒì†Œìœ ì" ì»¬ëŸ¼ì—ì„œ ëª¨ë“  ë„ì–´ì“°ê¸° ì œê±°
                if "ëŒ€ìƒì†Œìœ ì" in djg_df.columns:
                    djg_df["ëŒ€ìƒì†Œìœ ì"] = djg_df["ëŒ€ìƒì†Œìœ ì"].astype(str).str.replace(" ", "")
                
                djg_df = merge_same_row_if_amount_separated(djg_df)
                djg_df = trim_after_reference_note(djg_df)
                djg_df = extract_right_holders(djg_df)
                djg_df.insert(0, "í† ì§€ì£¼ì†Œ", name)
                
                djg_list.append(djg_df)
            else:
                # ë¹ˆ ë°ì´í„°í”„ë ˆì„ì—ë„ ëª¨ë“  ì—´ í¬í•¨ - ê¸°ë¡ìœ ë¬´ ì—´ ì œê±°
                djg_list.append(pd.DataFrame([[name, "ê¸°ë¡ì—†ìŒ", "", "", "", "", "", ""]], 
                                           columns=["í† ì§€ì£¼ì†Œ", "ìˆœìœ„ë²ˆí˜¸", "ë“±ê¸°ëª©ì ", "ì ‘ìˆ˜ì •ë³´", "ì£¼ìš”ë“±ê¸°ì‚¬í•­", "ëŒ€ìƒì†Œìœ ì", "ê·¼ì €ë‹¹ê¶Œì", "ì§€ìƒê¶Œì"]))

        except Exception as e:
            # UI í†µê³„ìš© ì˜¤ë¥˜ ì¹´ìš´íŒ… (ê¸°ì¡´ ë¡œì§ì— ì˜í–¥ ì—†ìŒ)
            error_type = f"íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {type(e).__name__}"
            excel_error_summary[error_type] = excel_error_summary.get(error_type, 0) + 1
            if len(excel_failed_samples) < 5:
                excel_failed_samples.append(f"{file_name} - {str(e)[:50]}...")
            excel_failure_count += 1
    
    # UI ì§„í–‰ë¥  ë°” ì™„ë£Œ ë° ê²°ê³¼ ìš”ì•½ í‘œì‹œ
    if total_excel_files > 0:
        excel_progress_bar.progress(1.0)
        excel_status_text.text("ì—‘ì…€ ì²˜ë¦¬ ì™„ë£Œ!")
        
        # ì—‘ì…€ ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½ ì¶œë ¥
        st.write("---")
        st.write(f"## ğŸ“Š ì—‘ì…€ íŒŒì¼ ë³€í™˜ ê²°ê³¼")
        
        # ì„±ê³µ/ì‹¤íŒ¨ í†µê³„
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("âœ… ì„±ê³µ", excel_success_count)
        with col2:
            st.metric("âŒ ì‹¤íŒ¨", excel_failure_count)
        with col3:
            st.metric("ğŸ“ ì „ì²´", total_excel_files)
        
        # ì„±ê³µë¥  í‘œì‹œ
        excel_success_rate = (excel_success_count / total_excel_files * 100) if total_excel_files > 0 else 0
        st.write(f"**ì„±ê³µë¥ : {excel_success_rate:.1f}%**")
        
        # ì„±ê³µ ì‚¬ë¡€ ìƒ˜í”Œ (ìµœëŒ€ 5ê°œ)
        if excel_successful_samples:
            st.write("### âœ… ì„±ê³µ ì‚¬ë¡€ (ìƒ˜í”Œ)")
            for sample in excel_successful_samples:
                st.write(f"- {sample}")
            if excel_success_count > 5:
                st.write(f"... ì™¸ {excel_success_count - 5}ê°œ ë”")
        
        # ì‹¤íŒ¨ ìœ í˜•ë³„ ìš”ì•½
        if excel_error_summary:
            st.write("### âŒ ì‹¤íŒ¨ ìœ í˜•ë³„ í†µê³„")
            for error_type, count in excel_error_summary.items():
                percentage = (count / excel_failure_count * 100) if excel_failure_count > 0 else 0
                st.write(f"- **{error_type}**: {count}ê°œ ({percentage:.1f}%)")
            
            # ì‹¤íŒ¨ ì‚¬ë¡€ ìƒ˜í”Œ (ìµœëŒ€ 5ê°œ)
            if excel_failed_samples:
                st.write("### ğŸ” ì‹¤íŒ¨ ì‚¬ë¡€ (ìƒ˜í”Œ)")
                for sample in excel_failed_samples:
                    st.write(f"- {sample}")
                if excel_failure_count > 5:
                    st.write(f"... ì™¸ {excel_failure_count - 5}ê°œ ë”")
    else:
        st.warning("ì—…ë¡œë“œëœ ZIP íŒŒì¼ì— Excel íŒŒì¼(.xlsx)ì´ ì—†ìŠµë‹ˆë‹¤.")
    wb = Workbook()
    for sheetname, data in zip(
        ["1. ì†Œìœ ì§€ë¶„í˜„í™© (ê°‘êµ¬)", "2. ì†Œìœ ê¶Œì‚¬í•­ (ê°‘êµ¬)", "3. ì €ë‹¹ê¶Œì‚¬í•­ (ì„êµ¬)"],
        [szj_list, syg_list, djg_list]
    ):
        ws = wb.create_sheet(title=sheetname)
        if data and sheetname == "1. ì†Œìœ ì§€ë¶„í˜„í™© (ê°‘êµ¬)":
            df = pd.concat(data, ignore_index=True)
            
            # "ì‚°" ì—´ ì¶”ê°€
            df["ì‚°"] = df["í† ì§€ì£¼ì†Œ"].apply(check_san_in_address)
            
            # ì—´ ìˆœì„œ ì¬ë°°ì¹˜ - "í† ì§€ì£¼ì†Œ" ë‹¤ìŒì— "ì‚°" ìœ„ì¹˜
            cols = df.columns.tolist()
            cols.remove("ì‚°")
            idx = cols.index("í† ì§€ì£¼ì†Œ")
            cols.insert(idx + 1, "ì‚°")
            df = df[cols]
            
            # í† ì§€ì£¼ì†Œ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (í•„í„° ì ìš© ì‹œ í…Œë‘ë¦¬ ìœ ì§€ë¥¼ ìœ„í•´)
            df = df.sort_values(by="í† ì§€ì£¼ì†Œ", ascending=True).reset_index(drop=True)
            
            # ì†Œìœ ì§€ë¶„í˜„í™©(ê°‘êµ¬) ì‹œíŠ¸ì—ëŠ” ê·¸ë£¹ í—¤ë” ì ìš©
            if any(df["ê·¸ë£¹ì •ë³´"] == "ìˆìŒ"):
                # ê·¸ë£¹ êµ¬ì¡° ì •ì˜ - "ì‚°" ì—´ ì¶”ê°€
                group_structure = {
                    "í† ì§€ì£¼ì†Œ": ["í† ì§€ì£¼ì†Œ", "ì‚°"],
                    "ì†Œìœ ì": ["ë“±ê¸°ëª…ì˜ì¸", "ì†Œìœ êµ¬ë¶„", "(ì£¼ë¯¼)ë“±ë¡ë²ˆí˜¸", "ì£¼ì†Œ", "ìˆœìœ„ë²ˆí˜¸"],
                    "í† ì§€": ["ìµœì¢…ì§€ë¶„", "ìµœì¢…ì§€ë¶„ ìˆ˜ì¹˜í™”", "ì§€ëª©", "í† ì§€ë©´ì ", "ì§€ë¶„ë©´ì "]
                }
                df = df.drop(columns=["ê·¸ë£¹ì •ë³´"])  # ê·¸ë£¹ì •ë³´ ì—´ ì œê±°
                create_grouped_headers(ws, df, group_structure)
                apply_top_border_on_change(ws, key_column_letter='A', start_row=3)
            else:
                df = df.drop(columns=["ê·¸ë£¹ì •ë³´"])  # ê·¸ë£¹ì •ë³´ ì—´ ì œê±°
                for r in dataframe_to_rows(df, index=False, header=True):
                    ws.append(r)
                # í—¤ë” í–‰ ìŠ¤íƒ€ì¼ ì ìš©
                style_header_row(ws)
        elif data:
            df = pd.concat(data, ignore_index=True)
            df.reset_index(drop=True, inplace=True)
            
            # í† ì§€ì£¼ì†Œ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (í•„í„° ì ìš© ì‹œ í…Œë‘ë¦¬ ìœ ì§€ë¥¼ ìœ„í•´)
            df = df.sort_values(by="í† ì§€ì£¼ì†Œ", ascending=True).reset_index(drop=True)
            
            if sheetname == "3. ì €ë‹¹ê¶Œì‚¬í•­ (ì„êµ¬)":
                if "ìˆœìœ„ë²ˆí˜¸" in df.columns and "ë“±ê¸°ëª©ì " in df.columns:
                    df = df.rename(columns={"ìˆœìœ„ë²ˆí˜¸": "ê¸°ë¡ìœ ë¬´"})
                    # ê¸°ë¡ìœ ë¬´ì— ë“±ê¸°ëª©ì  ê°’ë§Œ í‘œì‹œ (ë“±ê¸°ëª©ì ì´ ë¹„ì–´ìˆìœ¼ë©´ "ê¸°ë¡ì—†ìŒ")
                    df["ê¸°ë¡ìœ ë¬´"] = df["ë“±ê¸°ëª©ì "].apply(
                        lambda x: x if pd.notna(x) and str(x).strip() and str(x).strip() != "ê¸°ë¡ì—†ìŒ"
                        else "ê¸°ë¡ì—†ìŒ"
                    )
                    df = df.drop(columns=["ë“±ê¸°ëª©ì "])
            
            for r in dataframe_to_rows(df, index=False, header=True):
                ws.append(r)
            # Headers styling
            style_header_row(ws)
            apply_top_border_on_change(ws, key_column_letter='A', start_row=2)
        else:
            ws.append(["ê¸°ë¡ì—†ìŒ"])
            # ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°ì—ë„ í—¤ë” ìŠ¤íƒ€ì¼ ì ìš©
            style_header_row(ws)

    wb.remove(wb["Sheet"])
    with tempfile.NamedTemporaryFile(delete=False, suffix=".xlsx") as tmp:
        wb.save(tmp.name)
        excel_result_path = tmp.name

    # 2. PDF ZIP ì²˜ë¦¬ (ìˆì„ ë•Œë§Œ)
    pdf_result_path = None
    if uploaded_pdf_zip:
        temp_pdf_dir = tempfile.mkdtemp()
        temp_pdf_zip_path = os.path.join(temp_pdf_dir, "input_pdf.zip")
        with open(temp_pdf_zip_path, "wb") as f:
            f.write(uploaded_pdf_zip.read())
        extract_folder = os.path.join(temp_pdf_dir, "extracted")
        os.makedirs(extract_folder, exist_ok=True)
        pdf_result_path = os.path.join(temp_pdf_dir, "processed_result_pdf.zip")
        extract_and_process_pdf_zip(temp_pdf_zip_path, extract_folder, pdf_result_path)

    # 3. í†µí•© ê²°ê³¼ ZIP ìƒì„± ë° ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
    with tempfile.NamedTemporaryFile(delete=False, suffix=".zip") as final_zip:
        with zipfile.ZipFile(final_zip.name, 'w') as z:
            z.write(excel_result_path, arcname="ë“±ê¸°ì‚¬í•­_í†µí•©_ì‹œíŠ¸ë³„êµ¬ì„±.xlsx")
            if pdf_result_path and os.path.exists(pdf_result_path):
                z.write(pdf_result_path, arcname="PDF_íŒŒì¼ëª…_ì¼ê´„ë³€ê²½_ê²°ê³¼.zip")
        st.success("âœ… ë¶„ì„ ì™„ë£Œ! ì•„ë˜ì—ì„œ í†µí•© ê²°ê³¼ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”.")
        with open(final_zip.name, "rb") as f:
            st.download_button("ğŸ“¥ í†µí•© ê²°ê³¼ ZIP ë‹¤ìš´ë¡œë“œ (ì—‘ì…€+PDF)", data=f, file_name="í†µí•©_ê²°ê³¼.zip")

elif run_button and (not uploaded_zip):
    st.warning("ì—‘ì…€ ZIP íŒŒì¼ì„ ì—…ë¡œë“œí•´ì•¼ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
